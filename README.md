# üê≥ Docker-Python-Environments üê≥

## Ejemplo de aplicaci√≥n en PySpark con Streamlit

Este repositorio incluye una aplicaci√≥n de ejemplo que demuestra el uso pr√°ctico de Docker con Python, PySpark y Streamlit. La aplicaci√≥n est√° configurada para ejecutarse f√°cilmente usando Docker Compose y basada en una imagen con `spark` ya configurada.

### Estructura del proyecto de ejemplo

```
app.py                # Aplicaci√≥n Streamlit con PySpark
docker-compose.yml    # Configuraci√≥n para desplegar la aplicaci√≥n
Dockerfile            # Imagen Docker para la aplicaci√≥n
environment.yml       # Dependencias de Conda para el proyecto
```

### Caracter√≠sticas de la aplicaci√≥n

- **Verificaci√≥n del entorno PySpark**: Comprueba que PySpark funciona correctamente
- **Consultas SQL interactivas**: Permite ejecutar consultas Spark SQL desde la interfaz web
- **Visualizaci√≥n de datos**: Muestra resultados en tablas interactivas

### Vista previa de la aplicaci√≥n

![Ejemplo de la aplicaci√≥n PySpark con Streamlit](images/app_image.png)

### C√≥mo ejecutar la aplicaci√≥n

1. **Usando Docker Compose** (recomendado):

   ```bash
   docker-compose up --build
   ```

   La aplicaci√≥n estar√° disponible en: http://localhost:8501

2. **Construyendo manualmente**:

   ```bash
   # Construir la imagen
   docker build -t my-project-sol .
   
   # Ejecutar el contenedor
   docker run -it --rm -p 8501:8501 -p 4040:4040 -v "$(pwd)":/my-project-dir -w /my-project-dir my-project-sol bash -lc "streamlit run app.py"
   ```

### Detalles del Dockerfile

El Dockerfile principal utiliza la imagen base `lacamposm/docker-helpers:pyspark-conda-0.1.1` que incluye Python, Conda y PySpark preconfigurados. La aplicaci√≥n se ejecuta en un entorno Conda definido en `environment.yml`.

### Estructura de docker-compose.yml

El archivo docker-compose.yml configura:
- Construcci√≥n autom√°tica de la imagen
- Mapeo de puertos (8501 para Streamlit, 4040 para la UI de Spark)
- Montaje de vol√∫menes para el c√≥digo fuente
- Variables de entorno necesarias
- Comando para iniciar la aplicaci√≥n Streamlit

---

# üê≥ Docker Multitask Python Environments - Gu√≠a Completa üê≥

## Tabla de Contenidos
- [Introducci√≥n](#introducci√≥n)
  - [¬øQu√© es Docker?](#qu√©-es-docker)
  - [¬øQu√© es Python?](#qu√©-es-python)
  - [Python y Docker](#python-y-docker)
- [¬øPor qu√© usar Docker?](#por-qu√©-usar-docker)
- [Conceptos Clave](#conceptos-clave)
- [Principales Comandos de Docker](#principales-comandos-de-docker)
  - [Comandos Detallados](#comandos-detallados)
- [Im√°genes disponibles y uso](#im√°genes-disponibles-y-uso)
  - [Python Minimal (3.12-slim)](#dockerfile-pythonmin)
  - [Python Conda](#dockerfile-pythonconda)
  - [Python Conda Dev](#dockerfile-pythoncondasev)
  - [Python Poetry](#dockerfile-pythonpoetry)
  - [Python Poetry Dev](#dockerfile-poetrydev)
  - [Python Spark](#dockerfile-pythonspark)
- [Usos de Docker en Python](#usos-de-docker-en-python)
- [Desarrollo con VS Code DevContainer](#desarrollo-con-vs-code-devcontainer)
- [Publicaci√≥n de im√°genes en Docker Hub](#publicar-la-imagen-en-docker-hub)
- [Recomendaciones](#recomendaciones-al-trabajar-con-docker-y-python)
- [Conclusi√≥n](#conclusi√≥n)


### ¬øQu√© es Docker?

Docker es una plataforma que permite desarrollar, enviar y ejecutar aplicaciones dentro de contenedores. Un contenedor es un entorno ligero y aislado que contiene todo lo necesario para que una aplicaci√≥n funcione de forma consistente en cualquier lugar.

### ¬øQu√© es Python?

Python es un lenguaje de programaci√≥n interpretado, de alto nivel y prop√≥sito general conocido por su legibilidad y versatilidad. Su filosof√≠a de dise√±o enfatiza la simplicidad y la legibilidad del c√≥digo, lo que permite a los desarrolladores expresar conceptos en menos l√≠neas que en otros lenguajes. Python es ampliamente utilizado en an√°lisis de datos, inteligencia artificial, desarrollo web, automatizaci√≥n, y pr√°cticamente en cualquier campo de la programaci√≥n.

### Python y Docker

La combinaci√≥n de Python y Docker resuelve muchos desaf√≠os comunes en el desarrollo de software. Python, con su diversidad de versiones y dependencias, a menudo enfrenta el problema de "funciona en mi m√°quina". Docker soluciona esto al empaquetar la aplicaci√≥n Python junto con todas sus dependencias en un contenedor, asegurando un comportamiento uniforme en diferentes entornos. Esta combinaci√≥n es particularmente valiosa para equipos que trabajan en proyectos cient√≠ficos o soluciones de analitica de datos, donde la consistencia del entorno es crucial para obtener resultados reproducibles.

## ¬øPor qu√© usar Docker?

- **Aislamiento**: Cada contenedor cuenta con sus propias dependencias y librer√≠as, evitando conflictos con otras aplicaciones.  
- **Reproducibilidad**: Las aplicaciones se ejecutan de la misma manera indistintamente del sistema operativo anfitri√≥n.  
- **Escalabilidad**: Es sencillo replicar un contenedor y desplegarlo en distintos entornos sin configuraciones extra.  
- **Portabilidad**: Se puede exportar e importar contenedores sin importar la infraestructura subyacente.

## Conceptos Clave

- **Imagen**: Conjunto de capas que incluyen el sistema de archivos y la configuraci√≥n necesarios para ejecutar un contenedor.  
- **Contenedor**: Instancia de una imagen que se ejecuta de forma aislada y que puede crearse, iniciarse o detenerse f√°cilmente.  
- **Dockerfile**: Archivo que describe paso a paso c√≥mo se construye una imagen (instrucciones sobre instalaci√≥n de paquetes y configuraciones).  
- **Registro de im√°genes**: Repositorio donde se almacenan y comparten im√°genes de Docker (ej. Docker Hub).  

## Principales Comandos de Docker

Los comandos esenciales para trabajar con Docker son:

- `docker pull <imagen>`: Descarga una imagen desde un registro.
- `docker run <imagen>`: Crea y ejecuta un contenedor basado en la imagen.
- `docker ps`: Lista los contenedores en ejecuci√≥n.
- `docker stop <contenedor>`: Detiene un contenedor en ejecuci√≥n.
- `docker rm <contenedor>`: Elimina un contenedor detenido.
- `docker build -t <nombre_imagen> .`: Construye una imagen desde un Dockerfile.

### Comandos Detallados

1. `docker pull <imagen>`
    Descarga una imagen desde un registro.
    - `--all-tags, -a`: Descarga todas las etiquetas disponibles de la imagen.

2. `docker run <imagen>`
    Crea y ejecuta un contenedor basado en la imagen indicada.
    - `--detach, -d`: Ejecuta el contenedor en segundo plano.
    - `-it`: Permite una terminal interactiva.
    - `--volume, -v`: Monta un volumen.
    - `--name`: Asigna un nombre personalizado al contenedor.
    - `--rm`: Elimina autom√°ticamente el contenedor cuando se detiene.

3. `docker ps`
    Lista los contenedores en ejecuci√≥n.
    - `--all, -a`: Muestra todos los contenedores (no solo los activos).

4. `docker stop <contenedor>`
    Detiene un contenedor en ejecuci√≥n.
    - `--time, -t`: Segundos a esperar antes de forzar la detenci√≥n.

5. `docker rm <contenedor>`
    Elimina un contenedor que ya se ha detenido.
    - `--force, -f`: Fuerza la eliminaci√≥n de un contenedor en ejecuci√≥n.

6. `docker build -t <nombre_imagen> .`
    Construye una imagen usando un Dockerfile presente en el directorio actual.
    - `--no-cache`: No usa la cach√© durante la construcci√≥n.
    - `--file, -f`: Nombre del Dockerfile (por defecto es 'Dockerfile').

## Im√°genes disponibles y uso

### python-min/Dockerfile

Imagen m√≠nima de Python 3.12 para entornos ligeros sin paquetes adicionales.
Esta imagen se utiliza cuando se requiere un entorno base de Python sin dependencias extras, ideal para ejecutar scripts o aplicaciones simples de manera eficiente sin sobrecargar el contenedor.

```dockerfile
FROM python:3.12-slim

#  Set working directory for better layer caching
WORKDIR /workspace

#  Copy only requirements to cache dependencies layer
COPY requirements.txt .

#  Create venv, install dependencies, register kernel, 
# configure bashrc, and clean up in one layer
RUN set -eux; \
    python -m venv /opt/venv; \
    # ensure the virtualenv is activated in interactive shells
    echo 'source /opt/venv/bin/activate' >> /root/.bashrc; \
    /opt/venv/bin/pip install --no-cache-dir --upgrade pip; \
    /opt/venv/bin/pip install --no-cache-dir -r requirements.txt; \
    rm requirements.txt; \
    # register this environment as a Jupyter kernel
    /opt/venv/bin/python -m ipykernel install --sys-prefix --name venv --display-name "Python3.12 (venv)"

#  Prepend venv to PATH and ensure bash sources bashrc in non-interactive mode
ENV PATH="/opt/venv/bin:$PATH" \
    BASH_ENV="/root/.bashrc"

#  Expose Jupyter Notebook port
EXPOSE 8888

#  Launch bash (venv will be active via bashrc)
CMD ["bash"]
```

El archivo `requirements.txt` incluye:

```
jupyter
ipykernel
```

#### Ejecutar y Crear el Contenedor

Estando en la carpeta padre del proyecto:

##### Linux/MacOS


1. Construir la imagen de Docker:

     ```bash
     docker build -t python3.12-slim -f ./python-min/Dockerfile .
     ```

3. Ejecutar el contenedor montando la carpeta actual como volumen:
     ```sh
     docker run -it --rm -v "$(pwd)":/$(basename "$(pwd)") -w /$(basename "$(pwd)") python3.12-slim:latest
     ```

##### Windows

1. Construir la imagen de Docker:
     ```sh
     docker build -t python3.12-slim -f .\python-min\Dockerfile .
     ```
3. Ejecutar el contenedor montando la carpeta actual como volumen:

     ```powershell
     docker run -it --rm -v "${PWD}:/$(Split-Path -Leaf $PWD)" -w "/$(Split-Path -Leaf $PWD)" python3.12-slim:latest
     ```

     O en una l√≠nea m√°s legible usando el caracter de continuaci√≥n ` :
     ```powershell
     docker run -it --rm `
          -v "${PWD}:/$(Split-Path -Leaf $PWD)" `
          -w "/$(Split-Path -Leaf $PWD)" `
          python3.12-slim:latest
     ```

### conda/Dockerfile

Imagen basada en Miniconda para entornos de desarrollo cient√≠fico.

```dockerfile
FROM continuumio/miniconda3:24.10.0-1

LABEL maintainer="lacamposm <lacamposm@unal.edu.co>" \
      version="0.1.1" \
      description="Python 3.11 with conda for base image analytic projects"

RUN apt-get update && apt-get install -y --no-install-recommends \
    bash \
    build-essential \
    ca-certificates \
    curl \
    libnss3 \
    make \
    sudo \
    wget \
    && apt-get clean \
    && rm -rf /var/lib/apt/lists/*

CMD ["/bin/bash"]
```

#### Ejecutar y Crear el Contenedor

Estando en la carpeta padre del proyecto:

##### Linux/MacOS

1. Construir la imagen de Docker:
     ```sh
     docker build -t python-conda -f ./conda/Dockerfile .
     ```

2. Ejecutar el contenedor montando la carpeta actual como volumen:
     ```sh
     docker run -it --rm -v "$(pwd)":/$(basename "$(pwd)") -w /$(basename "$(pwd)") python-conda:latest
     ```

##### Windows

1. Construir la imagen de Docker:
     ```powershell
     docker build -t python-conda -f .\conda\Dockerfile .
     ```

2. Ejecutar el contenedor montando la carpeta actual como volumen:
     ```powershell
     docker run -it --rm `
     -v "${PWD}:/$(Split-Path -Leaf $PWD)" `
     -w "/$(Split-Path -Leaf $PWD)" `
     python-conda:latest
     ```

### conda/Dockerfile.dev

Versi√≥n extendida para desarrollo con Node.js y otras herramientas adicionales.

```dockerfile
# Imagen base misma que en latest de conda/Dockerfile
FROM continuumio/miniconda3:24.10.0-1

LABEL maintainer="lacamposm <lacamposm@unal.edu.co>" \
      version="0.1.1" \
      description="Python 3.11 with conda for base image dev-version"

# Actualizar repositorios e instalar utilidades esenciales para desarrollo
RUN apt-get update && apt-get install -y --no-install-recommends \
    bash \
    build-essential \
    ca-certificates \
    curl \
    git \
    libnss3 \
    make \
    sudo \
    wget \
    && curl -fsSL https://deb.nodesource.com/setup_20.x | bash - \
    && apt-get update && apt-get install -y --no-install-recommends nodejs \
    && node -v && npm -v \
    && git config --system core.sshCommand "ssh -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no" \
    && git config --system --add safe.directory "*" \
    && apt-get clean && rm -rf /var/lib/apt/lists/*

CMD ["/bin/bash"]
```

#### Ejecutar y Crear el Contenedor

##### Linux/MacOS

1. Construir la imagen de Docker:
     ```sh
     docker build -t python-conda-dev -f ./conda/Dockerfile.dev .
     ```

2. Ejecutar el contenedor montando la carpeta actual como volumen:
     ```sh
     docker run -it --rm -v "$(pwd)":/$(basename "$(pwd)") -w /$(basename "$(pwd)") python-conda-dev:latest
     ```

##### Windows

1. Construir la imagen de Docker:
     ```powershell
     docker build -t python-conda-dev -f .\conda\Dockerfile.dev .
     ```

2. Ejecutar el contenedor montando la carpeta actual como volumen:
     ```powershell
     docker run -it --rm `
     -v "${PWD}:/$(Split-Path -Leaf $PWD)" `
     -w "/$(Split-Path -Leaf $PWD)" `
     python-conda-dev:latest
     ```

### poetry/Dockerfile

Imagen b√°sica con Python 3.12-slim y Poetry para gesti√≥n de dependencias.

```dockerfile
FROM python:3.12.10

LABEL maintainer="lacamposm <lacamposm@unal.edu.co>" \
      version="0.1.1" \
      description="Python 3.12.10 + Poetry"

ENV POETRY_HOME="/opt/poetry"
ENV PATH="${POETRY_HOME}/bin:${PATH}"

RUN apt-get update \
    && apt-get install -y --no-install-recommends \
    bash build-essential ca-certificates curl git make wget \
    && rm -rf /var/lib/apt/lists/* \
    && pip install --no-cache-dir --upgrade pip --root-user-action=ignore \
    && curl -sSL https://install.python-poetry.org | python3 - \
    && poetry config virtualenvs.create false \
    && rm -rf /root/.cache/pypoetry/*

CMD ["/bin/bash"]
```

#### Ejecutar y Crear el Contenedor

Estando en la carpeta padre del proyecto:

##### Linux/MacOS

1. Construir la imagen de Docker:
     ```sh
     docker build -t python-poetry -f ./poetry/Dockerfile .
     ```

2. Ejecutar el contenedor montando la carpeta actual como volumen:
     ```sh
     docker run -it --rm -v "$(pwd)":/$(basename "$(pwd)") -w /$(basename "$(pwd)") python-poetry:latest
     ```

##### Windows

1. Construir la imagen de Docker:
     ```powershell
     docker build -t python-poetry -f .\poetry\Dockerfile .
     ```

2. Ejecutar el contenedor montando la carpeta actual como volumen:
     ```powershell
     docker run -it --rm `
     -v "${PWD}:/$(Split-Path -Leaf $PWD)" `
     -w "/$(Split-Path -Leaf $PWD)" `
     python-poetry:latest
     ```

### spark/Dockerfile

Imagen con Python Conda y Apache Spark para procesamiento de datos distribuido.

```dockerfile
# Use the same base image as the main Dockerfile
# For more information:
#   - https://hub.docker.com/r/lacamposm/docker-helpers
#   - https://github.com/lacamposm/desarrollo-analitico-oic
FROM lacamposm/docker-helpers:python-conda-base-0.1.1

LABEL maintainer="lacamposm <lacamposm@unal.edu.co>" \
      version="0.1.1" \
      description="Python 3.12.10 + Spark 3.5.5"

# Install dependencies, configure system, and setup directories in a single layer
# to reduce image size and number of layers  
RUN mkdir -p /my-project-dir /data/_tmp && \
    chmod -R 777 /data/_tmp && \
    apt-get update && \
    apt-get install -y --no-install-recommends \
        bash-completion \
        locales \
        openjdk-17-jre-headless && \
    rm -rf /var/lib/apt/lists/* && \
    wget -q https://archive.apache.org/dist/spark/spark-3.5.5/spark-3.5.5-bin-hadoop3.tgz && \
    tar -xzf spark-3.5.5-bin-hadoop3.tgz && \
    mv spark-3.5.5-bin-hadoop3 /opt/spark && \
    rm spark-3.5.5-bin-hadoop3.tgz && \
    rm -rf /tmp/* /root/.cache /root/.wget-hsts

# Configure environment variables.
ENV SPARK_HOME=/opt/spark
ENV PATH=$PATH:$SPARK_HOME/bin:$SPARK_HOME/sbin
ENV JAVA_HOME=/usr/lib/jvm/java-17-openjdk-amd64
ENV PATH=$JAVA_HOME/bin:$PATH

# Expose ports for Spark UI, FastAPI, Streamlit, Jupyter
EXPOSE 4040 8000 8501 8888

CMD ["/bin/bash"]
```

### spark/Dockerfile.dev

Versi√≥n extendida para desarrollo con herramientas adicionales y base en python-conda-dev.

```dockerfile
# Use the same base image as the main Dockerfile
# For more information:
#   - https://hub.docker.com/r/lacamposm/docker-helpers
#   - https://github.com/lacamposm/desarrollo-analitico-oic
FROM lacamposm/docker-helpers:python-conda-base-0.1.1-dev

LABEL maintainer="lacamposm <lacamposm@unal.edu.co>" \
      version="0.1.1" \
      description="Python 3.12.10 + Spark 3.5.5, dev-version"

# Install dependencies, configure system, and setup directories in a single layer
# to reduce image size and number of layers  
RUN mkdir -p /my-project-dir /data/_tmp && \
    chmod -R 777 /data/_tmp && \
    apt-get update && \
    apt-get install -y --no-install-recommends \
        bash-completion \
        locales \
        openjdk-17-jre-headless && \
    rm -rf /var/lib/apt/lists/* && \
    wget -q https://archive.apache.org/dist/spark/spark-3.5.5/spark-3.5.5-bin-hadoop3.tgz && \
    tar -xzf spark-3.5.5-bin-hadoop3.tgz && \
    mv spark-3.5.5-bin-hadoop3 /opt/spark && \
    rm spark-3.5.5-bin-hadoop3.tgz && \
    rm -rf /tmp/* /root/.cache /root/.wget-hsts

# Configure environment variables.
ENV SPARK_HOME=/opt/spark
ENV PATH=$PATH:$SPARK_HOME/bin:$SPARK_HOME/sbin
ENV JAVA_HOME=/usr/lib/jvm/java-17-openjdk-amd64
ENV PATH=$JAVA_HOME/bin:$PATH

# Expose ports for Spark UI, FastAPI, Streamlit, Jupyter
EXPOSE 4040 8000 8501 8888

CMD ["/bin/bash"]
```

#### Ejecutar y Crear el Contenedor

Estando en la carpeta padre del proyecto:

##### Linux/MacOS

1. Construir la imagen de Docker:
     ```sh
     docker build -t python-spark -f ./spark/Dockerfile .
     ```

2. Ejecutar el contenedor montando la carpeta actual como volumen:
     ```sh
     docker run -it --rm -v "$(pwd)":/$(basename "$(pwd)") -w /$(basename "$(pwd)") python-spark:latest
     ```

3. Para la versi√≥n de desarrollo:
     ```sh
     docker build -t python-spark-dev -f ./spark/Dockerfile.dev .
     docker run -it --rm -v "$(pwd)":/$(basename "$(pwd)") -w /$(basename "$(pwd)") python-spark-dev:latest
     ```

##### Windows

1. Construir la imagen de Docker:
     ```powershell
     docker build -t python-spark -f .\spark\Dockerfile .
     ```

2. Ejecutar el contenedor montando la carpeta actual como volumen:
     ```powershell
     docker run -it --rm `
     -v "${PWD}:/$(Split-Path -Leaf $PWD)" `
     -w "/$(Split-Path -Leaf $PWD)" `
     python-spark:latest
     ```

3. Para la versi√≥n de desarrollo:
     ```powershell
     docker build -t python-spark-dev -f .\spark\Dockerfile.dev .
     docker run -it --rm `
     -v "${PWD}:/$(Split-Path -Leaf $PWD)" `
     -w "/$(Split-Path -Leaf $PWD)" `
     python-spark-dev:latest
     ```

## Usos de Docker en Python

- **Entornos de desarrollo**: Facilita la creaci√≥n de entornos personalizados que incluyan la versi√≥n de Python y las dependencias necesarias para cada proyecto.  
- **Pruebas y validaci√≥n**: Se pueden ejecutar tests en contenedores limpios, reproduciendo condiciones id√©nticas sin afectar la configuraci√≥n del sistema local.  
- **Despliegue en producci√≥n**: Una vez validada la aplicaci√≥n, se despliega el mismo contenedor en el entorno de producci√≥n, lo que reduce los errores por diferencias de configuraci√≥n.  

## Desarrollo con VS Code DevContainer

Para facilitar el desarrollo aislado con VS Code, se provee un DevContainer configurado en la carpeta `.devcontainer`:

1.  **Construir y levantar** el contenedor con Docker Compose:

    ```sh
    docker compose -f .devcontainer/docker-compose-dev.yml up --build
    ```

2.  **Contexto y Dockerfile** usados:
    *   Contexto: `.` (directorio ra√≠z del proyecto)
    *   Dockerfile: `.devcontainer/Dockerfile.dev`
    *   Archivo de entorno: `.devcontainer/environment.dev.yml`

3.  **Acceder** al contenedor:
    ```sh
    docker exec -it dev-name-project bash
    ```

4.  **Reabrir en contenedor** desde VS Code (gu√≠a r√°pida):
    *   Ctrl+Shift+P ‚Üí _Dev Containers: Rebuild and Reopen in Container_

**‚û°Ô∏è Para m√°s detalles sobre la configuraci√≥n del Dev Container, consulta el [README espec√≠fico de .devcontainer](./.devcontainer/README.md).**

## Publicar la Imagen en Docker Hub

Para publicar las im√°genes en Docker Hub, sigue estos pasos:

1. Inicia sesi√≥n en Docker Hub:
     ```sh
     docker login
     ```
     Ingresa tu nombre de usuario y contrase√±a cuando se solicite.

2. Etiquetar las im√°genes
   Para subir una imagen a tu repositorio en Docker Hub, primero debes etiquetarla con tu nombre de usuario:

     Para PythonMin:
     ```sh
     docker tag python3.12-slim tu-usuario-dockerhub/nombre-asignado:python3.12-slim
     ```
     Para PythonConda:
     ```sh
     docker tag python-conda tu-usuario-dockerhub/nombre-asignado:python-conda
     ```
     Para PythonCondaDev:
     ```sh
     docker tag python-conda-dev tu-usuario-dockerhub/nombre-asignado:python-conda-dev
     ```
     Para PythonPoetry:
     ```sh
     docker tag python-poetry tu-usuario-dockerhub/nombre-asignado:python-poetry
     ```
     Para PythonSpark:
     ```sh
     docker tag python-spark tu-usuario-dockerhub/nombre-asignado:python-spark
     ```

3. Subir las im√°genes a Docker Hub
   Una vez etiquetadas, puedes subirlas a Docker Hub:

     Para PythonMin:
     ```sh
     docker push tu-usuario-dockerhub/nombre-asignado:python3.12-slim
     ```
     Para PythonConda:
     ```sh
     docker push tu-usuario-dockerhub/nombre-asignado:python-conda
     ```
     Para PythonCondaDev:
     ```sh
     docker push tu-usuario-dockerhub/nombre-asignado:python-conda-dev
     ```
     Para PythonPoetry:
     ```sh
     docker push tu-usuario-dockerhub/nombre-asignado:python-poetry
     ```
     Para PythonSpark:
     ```sh
     docker push tu-usuario-dockerhub/nombre-asignado:python-spark
     ```

4. Descargar y utilizar im√°genes desde Docker Hub
   Para descargar y usar una imagen publicada:

     ```sh
     docker pull tu-usuario-dockerhub/nombre-asignado:python-conda-dev
     ```

     Para Linux:
     ```sh
     docker run -it --rm -v "$(pwd)":/$(basename "$(pwd)") -w /$(basename "$(pwd)") tu-usuario-dockerhub/nombre-asignado:python-conda-dev
     ```

     Para Windows:
     ```powershell
     docker run -it --rm -v "${PWD}:/$(Split-Path -Leaf $PWD)" -w "/$(Split-Path -Leaf $PWD)" tu-usuario-dockerhub/nombre-asignado:python-conda-dev
     ```

     Aseg√∫rate de reemplazar `tu-usuario-dockerhub` con tu nombre de usuario en Docker Hub si est√°s subiendo tus propias im√°genes.

5. Explicaci√≥n de los par√°metros
     - `-it`: Permite la interacci√≥n con el contenedor.
     - `--rm`: Elimina el contenedor al detenerse.
     - `-v "$(pwd):/$(basename "$(pwd)")"`: Monta el directorio actual en el contenedor.
     - `-w /$(basename "$(pwd)")"`: Define el directorio de trabajo.

## Recomendaciones al Trabajar con Docker y Python

- Incluir siempre un archivo con las dependencias (por ejemplo, `requirements.txt`, `pyproject.toml` o `environment.yml` para Conda) para que la instalaci√≥n sea clara y reproducible.
- Considerar Conda como alternativa para gestionar entornos Python dentro de contenedores, especialmente para proyectos cient√≠ficos o con dependencias complejas.
- Al usar Conda con Docker, preferir im√°genes base como `continuumio/miniconda3` que ya incluyen el sistema de gesti√≥n de paquetes preinstalado.  
- Mantener las im√°genes lo m√°s ligeras posible para disminuir tiempos de descarga y consumo de recursos.  
- Usar herramientas de orquestaci√≥n como Docker Compose o Kubernetes para coordinar varios contenedores (ej. bases de datos, servidores web, etc.).  

## Conclusi√≥n

Docker ha transformado radicalmente la forma en que desarrollamos, probamos y desplegamos aplicaciones, tanto en Python como en otros lenguajes. Al encapsular cada entorno en contenedores, se garantiza una ejecuci√≥n uniforme y predecible en cualquier plataforma, eliminando de ra√≠z el cl√°sico problema de "en mi m√°quina funciona". 

### Ventajas Destacadas

- **Uniformidad**: Garantiza ejecuci√≥n id√©ntica en cualquier plataforma, simplificando la depuraci√≥n.
- **Eficiencia**: Contenedores m√°s ligeros y r√°pidos que m√°quinas virtuales, optimizando recursos.
- **CI/CD**: Integraci√≥n fluida con pipelines de desarrollo automatizado.
- **Microservicios**: Facilita arquitecturas modulares con componentes independientes.
- **Persistencia**: Mediante vol√∫menes, separa c√≥digo inmutable de datos persistentes.

Para los desarrolladores de Python, Docker no solo resuelve problemas hist√≥ricos relacionados con la gesti√≥n de versiones y conflictos de dependencias, sino que establece un flujo de trabajo moderno y robusto. En un mundo cada vez m√°s orientado hacia infraestructuras cloud-native y metodolog√≠as √°giles, Docker se consolida como una herramienta esencial en el ecosistema DevOps, facilitando procesos de desarrollo m√°s eficientes, colaborativos y escalables.