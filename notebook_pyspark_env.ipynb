{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Test Notebook with pyspark-env***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# conda environments:\n",
      "#\n",
      "base                     /opt/conda\n",
      "pyspark-env           *  /opt/conda/envs/pyspark-env\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda env list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.12.10\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# packages in environment at /opt/conda/envs/pyspark-env:\n",
      "#\n",
      "# Name                    Version                   Build  Channel\n",
      "_libgcc_mutex             0.1                 conda_forge    conda-forge\n",
      "_openmp_mutex             4.5                       2_gnu    conda-forge\n",
      "alabaster                 1.0.0                    pypi_0    pypi\n",
      "anyio                     4.9.0                    pypi_0    pypi\n",
      "argon2-cffi               23.1.0                   pypi_0    pypi\n",
      "argon2-cffi-bindings      21.2.0                   pypi_0    pypi\n",
      "arrow                     1.3.0                    pypi_0    pypi\n",
      "asttokens                 3.0.0                    pypi_0    pypi\n",
      "async-lru                 2.0.5                    pypi_0    pypi\n",
      "attrs                     25.3.0                   pypi_0    pypi\n",
      "aws-c-auth                0.9.0                h0a147a0_3    conda-forge\n",
      "aws-c-cal                 0.9.0                hada3f3f_0    conda-forge\n",
      "aws-c-common              0.12.2               hb9d3cd8_0    conda-forge\n",
      "aws-c-compression         0.3.1                hc2d532b_4    conda-forge\n",
      "aws-c-event-stream        0.5.4                hc5e5e9e_7    conda-forge\n",
      "aws-c-http                0.9.7                h6884c39_1    conda-forge\n",
      "aws-c-io                  0.18.1               h1a9f769_2    conda-forge\n",
      "aws-c-mqtt                0.12.3               h27aa219_3    conda-forge\n",
      "aws-c-s3                  0.7.15               hea6d4b9_2    conda-forge\n",
      "aws-c-sdkutils            0.2.3                hc2d532b_4    conda-forge\n",
      "aws-checksums             0.2.7                hc2d532b_0    conda-forge\n",
      "aws-crt-cpp               0.32.4               h9a0fb62_1    conda-forge\n",
      "aws-sdk-cpp               1.11.510             h5b777a2_6    conda-forge\n",
      "azure-core-cpp            1.14.0               h5cfcd09_0    conda-forge\n",
      "azure-identity-cpp        1.10.0               h113e628_0    conda-forge\n",
      "azure-storage-blobs-cpp   12.13.0              h3cf044e_1    conda-forge\n",
      "azure-storage-common-cpp  12.8.0               h736e048_1    conda-forge\n",
      "azure-storage-files-datalake-cpp 12.12.0              ha633028_1    conda-forge\n",
      "babel                     2.17.0                   pypi_0    pypi\n",
      "beautifulsoup4            4.13.4                   pypi_0    pypi\n",
      "bleach                    6.2.0                    pypi_0    pypi\n",
      "bzip2                     1.0.8                h4bc722e_7    conda-forge\n",
      "c-ares                    1.34.5               hb9d3cd8_0    conda-forge\n",
      "ca-certificates           2025.4.26            hbd8a1cb_0    conda-forge\n",
      "certifi                   2025.4.26                pypi_0    pypi\n",
      "cffi                      1.17.1                   pypi_0    pypi\n",
      "charset-normalizer        3.4.1                    pypi_0    pypi\n",
      "comm                      0.2.2                    pypi_0    pypi\n",
      "debugpy                   1.8.14                   pypi_0    pypi\n",
      "decorator                 5.2.1                    pypi_0    pypi\n",
      "defusedxml                0.7.1                    pypi_0    pypi\n",
      "docutils                  0.21.2                   pypi_0    pypi\n",
      "executing                 2.2.0                    pypi_0    pypi\n",
      "fastjsonschema            2.21.1                   pypi_0    pypi\n",
      "fqdn                      1.5.1                    pypi_0    pypi\n",
      "gflags                    2.2.2             h5888daf_1005    conda-forge\n",
      "glog                      0.7.1                hbabe93e_0    conda-forge\n",
      "h11                       0.16.0                   pypi_0    pypi\n",
      "httpcore                  1.0.9                    pypi_0    pypi\n",
      "httpx                     0.28.1                   pypi_0    pypi\n",
      "idna                      3.10                     pypi_0    pypi\n",
      "imagesize                 1.4.1                    pypi_0    pypi\n",
      "ipykernel                 6.29.5                   pypi_0    pypi\n",
      "ipython                   9.2.0                    pypi_0    pypi\n",
      "ipython-pygments-lexers   1.1.1                    pypi_0    pypi\n",
      "ipywidgets                8.1.6                    pypi_0    pypi\n",
      "isoduration               20.11.0                  pypi_0    pypi\n",
      "jedi                      0.19.2                   pypi_0    pypi\n",
      "jinja2                    3.1.6                    pypi_0    pypi\n",
      "json5                     0.12.0                   pypi_0    pypi\n",
      "jsonpointer               3.0.0                    pypi_0    pypi\n",
      "jsonschema                4.23.0                   pypi_0    pypi\n",
      "jsonschema-specifications 2025.4.1                 pypi_0    pypi\n",
      "jupyter                   1.1.1                    pypi_0    pypi\n",
      "jupyter-client            8.6.3                    pypi_0    pypi\n",
      "jupyter-console           6.6.3                    pypi_0    pypi\n",
      "jupyter-core              5.7.2                    pypi_0    pypi\n",
      "jupyter-events            0.12.0                   pypi_0    pypi\n",
      "jupyter-lsp               2.2.5                    pypi_0    pypi\n",
      "jupyter-server            2.15.0                   pypi_0    pypi\n",
      "jupyter-server-terminals  0.5.3                    pypi_0    pypi\n",
      "jupyterlab                4.4.1                    pypi_0    pypi\n",
      "jupyterlab-pygments       0.3.0                    pypi_0    pypi\n",
      "jupyterlab-server         2.27.3                   pypi_0    pypi\n",
      "jupyterlab-widgets        3.0.14                   pypi_0    pypi\n",
      "keyutils                  1.6.1                h166bdaf_0    conda-forge\n",
      "krb5                      1.21.3               h659f571_0    conda-forge\n",
      "ld_impl_linux-64          2.43                 h712a8e2_4    conda-forge\n",
      "libabseil                 20250127.1      cxx17_hbbce691_0    conda-forge\n",
      "libarrow                  20.0.0           h27f8bab_0_cpu    conda-forge\n",
      "libarrow-acero            20.0.0           hcb10f89_0_cpu    conda-forge\n",
      "libarrow-dataset          20.0.0           hcb10f89_0_cpu    conda-forge\n",
      "libarrow-substrait        20.0.0           h1bed206_0_cpu    conda-forge\n",
      "libblas                   3.9.0           31_h59b9bed_openblas    conda-forge\n",
      "libbrotlicommon           1.1.0                hb9d3cd8_2    conda-forge\n",
      "libbrotlidec              1.1.0                hb9d3cd8_2    conda-forge\n",
      "libbrotlienc              1.1.0                hb9d3cd8_2    conda-forge\n",
      "libcblas                  3.9.0           31_he106b2a_openblas    conda-forge\n",
      "libcrc32c                 1.1.2                h9c3ff4c_0    conda-forge\n",
      "libcurl                   8.13.0               h332b0f4_0    conda-forge\n",
      "libedit                   3.1.20250104    pl5321h7949ede_0    conda-forge\n",
      "libev                     4.33                 hd590300_2    conda-forge\n",
      "libevent                  2.1.12               hf998b51_1    conda-forge\n",
      "libexpat                  2.7.0                h5888daf_0    conda-forge\n",
      "libffi                    3.4.6                h2dba641_1    conda-forge\n",
      "libgcc                    14.2.0               h767d61c_2    conda-forge\n",
      "libgcc-ng                 14.2.0               h69a702a_2    conda-forge\n",
      "libgfortran               14.2.0               h69a702a_2    conda-forge\n",
      "libgfortran5              14.2.0               hf1ad2bd_2    conda-forge\n",
      "libgomp                   14.2.0               h767d61c_2    conda-forge\n",
      "libgoogle-cloud           2.36.0               hc4361e1_1    conda-forge\n",
      "libgoogle-cloud-storage   2.36.0               h0121fbd_1    conda-forge\n",
      "libgrpc                   1.71.0               h8e591d7_1    conda-forge\n",
      "libiconv                  1.18                 h4ce23a2_1    conda-forge\n",
      "liblapack                 3.9.0           31_h7ac8fdf_openblas    conda-forge\n",
      "liblzma                   5.8.1                hb9d3cd8_0    conda-forge\n",
      "libnghttp2                1.64.0               h161d5f1_0    conda-forge\n",
      "libnsl                    2.0.1                hd590300_0    conda-forge\n",
      "libopenblas               0.3.29          pthreads_h94d23a6_0    conda-forge\n",
      "libopentelemetry-cpp      1.20.0               hd1b1c89_0    conda-forge\n",
      "libopentelemetry-cpp-headers 1.20.0               ha770c72_0    conda-forge\n",
      "libparquet                20.0.0           h081d1f1_0_cpu    conda-forge\n",
      "libprotobuf               5.29.3               h501fc15_1    conda-forge\n",
      "libre2-11                 2024.07.02           hba17884_3    conda-forge\n",
      "libsqlite                 3.49.1               hee588c1_2    conda-forge\n",
      "libssh2                   1.11.1               hcf80075_0    conda-forge\n",
      "libstdcxx                 14.2.0               h8f9b012_2    conda-forge\n",
      "libstdcxx-ng              14.2.0               h4852527_2    conda-forge\n",
      "libthrift                 0.21.0               h0e7cc3e_0    conda-forge\n",
      "libutf8proc               2.10.0               h4c51ac1_0    conda-forge\n",
      "libuuid                   2.38.1               h0b41bf4_0    conda-forge\n",
      "libxcrypt                 4.4.36               hd590300_1    conda-forge\n",
      "libxml2                   2.13.7               h81593ed_1    conda-forge\n",
      "libzlib                   1.3.1                hb9d3cd8_2    conda-forge\n",
      "lz4-c                     1.10.0               h5888daf_1    conda-forge\n",
      "markupsafe                3.0.2                    pypi_0    pypi\n",
      "matplotlib-inline         0.1.7                    pypi_0    pypi\n",
      "mistune                   3.1.3                    pypi_0    pypi\n",
      "nbclient                  0.10.2                   pypi_0    pypi\n",
      "nbconvert                 7.16.6                   pypi_0    pypi\n",
      "nbformat                  5.10.4                   pypi_0    pypi\n",
      "ncurses                   6.5                  h2d0b736_3    conda-forge\n",
      "nest-asyncio              1.6.0                    pypi_0    pypi\n",
      "nlohmann_json             3.12.0               h3f2d84a_0    conda-forge\n",
      "notebook                  7.4.1                    pypi_0    pypi\n",
      "notebook-shim             0.2.4                    pypi_0    pypi\n",
      "numpy                     1.26.4          py312heda63a1_0    conda-forge\n",
      "openssl                   3.5.0                h7b32b05_0    conda-forge\n",
      "orc                       2.1.1                h17f744e_1    conda-forge\n",
      "overrides                 7.7.0                    pypi_0    pypi\n",
      "packaging                 25.0                     pypi_0    pypi\n",
      "pandas                    2.2.3           py312hf9745cd_3    conda-forge\n",
      "pandocfilters             1.5.1                    pypi_0    pypi\n",
      "parso                     0.8.4                    pypi_0    pypi\n",
      "pexpect                   4.9.0                    pypi_0    pypi\n",
      "pip                       25.1               pyh8b19718_0    conda-forge\n",
      "platformdirs              4.3.7                    pypi_0    pypi\n",
      "prometheus-client         0.21.1                   pypi_0    pypi\n",
      "prometheus-cpp            1.3.0                ha5d0236_0    conda-forge\n",
      "prompt-toolkit            3.0.51                   pypi_0    pypi\n",
      "psutil                    7.0.0                    pypi_0    pypi\n",
      "ptyprocess                0.7.0                    pypi_0    pypi\n",
      "pure-eval                 0.2.3                    pypi_0    pypi\n",
      "py4j                      0.10.9.7           pyhd8ed1ab_0    conda-forge\n",
      "pyarrow                   20.0.0          py312h7900ff3_0    conda-forge\n",
      "pyarrow-core              20.0.0          py312h01725c0_0_cpu    conda-forge\n",
      "pycparser                 2.22                     pypi_0    pypi\n",
      "pygments                  2.19.1                   pypi_0    pypi\n",
      "pyspark                   3.5.5              pyhd8ed1ab_0    conda-forge\n",
      "python                    3.12.10         h9e4cc4f_0_cpython    conda-forge\n",
      "python-dateutil           2.9.0.post0        pyhff2d567_1    conda-forge\n",
      "python-json-logger        3.3.0                    pypi_0    pypi\n",
      "python-tzdata             2025.2             pyhd8ed1ab_0    conda-forge\n",
      "python_abi                3.12                    7_cp312    conda-forge\n",
      "pytz                      2025.2             pyhd8ed1ab_0    conda-forge\n",
      "pyyaml                    6.0.2                    pypi_0    pypi\n",
      "pyzmq                     26.4.0                   pypi_0    pypi\n",
      "re2                       2024.07.02           h9925aae_3    conda-forge\n",
      "readline                  8.2                  h8c095d6_2    conda-forge\n",
      "referencing               0.36.2                   pypi_0    pypi\n",
      "requests                  2.32.3                   pypi_0    pypi\n",
      "rfc3339-validator         0.1.4                    pypi_0    pypi\n",
      "rfc3986-validator         0.1.1                    pypi_0    pypi\n",
      "roman-numerals-py         3.1.0                    pypi_0    pypi\n",
      "rpds-py                   0.24.0                   pypi_0    pypi\n",
      "s2n                       1.5.17               hba75a32_0    conda-forge\n",
      "send2trash                1.8.3                    pypi_0    pypi\n",
      "setuptools                80.1.0             pyhff2d567_0    conda-forge\n",
      "six                       1.17.0             pyhd8ed1ab_0    conda-forge\n",
      "snappy                    1.2.1                h8bd8927_1    conda-forge\n",
      "sniffio                   1.3.1                    pypi_0    pypi\n",
      "snowballstemmer           2.2.0                    pypi_0    pypi\n",
      "soupsieve                 2.7                      pypi_0    pypi\n",
      "sphinx                    8.2.3                    pypi_0    pypi\n",
      "sphinxcontrib-applehelp   2.0.0                    pypi_0    pypi\n",
      "sphinxcontrib-devhelp     2.0.0                    pypi_0    pypi\n",
      "sphinxcontrib-htmlhelp    2.1.0                    pypi_0    pypi\n",
      "sphinxcontrib-jsmath      1.0.1                    pypi_0    pypi\n",
      "sphinxcontrib-qthelp      2.0.0                    pypi_0    pypi\n",
      "sphinxcontrib-serializinghtml 2.0.0                    pypi_0    pypi\n",
      "stack-data                0.6.3                    pypi_0    pypi\n",
      "terminado                 0.18.1                   pypi_0    pypi\n",
      "tinycss2                  1.4.0                    pypi_0    pypi\n",
      "tk                        8.6.13          noxft_h4845f30_101    conda-forge\n",
      "tornado                   6.4.2                    pypi_0    pypi\n",
      "traitlets                 5.14.3                   pypi_0    pypi\n",
      "types-python-dateutil     2.9.0.20241206           pypi_0    pypi\n",
      "typing-extensions         4.13.2                   pypi_0    pypi\n",
      "tzdata                    2025b                h78e105d_0    conda-forge\n",
      "uri-template              1.3.0                    pypi_0    pypi\n",
      "urllib3                   2.4.0                    pypi_0    pypi\n",
      "wcwidth                   0.2.13                   pypi_0    pypi\n",
      "webcolors                 24.11.1                  pypi_0    pypi\n",
      "webencodings              0.5.1                    pypi_0    pypi\n",
      "websocket-client          1.8.0                    pypi_0    pypi\n",
      "wheel                     0.45.1             pyhd8ed1ab_1    conda-forge\n",
      "widgetsnbextension        4.0.14                   pypi_0    pypi\n",
      "zlib                      1.3.1                hb9d3cd8_2    conda-forge\n",
      "zstd                      1.5.7                hb8e6e7a_2    conda-forge\n"
     ]
    }
   ],
   "source": [
    "!conda list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas version: 2.2.3\n",
      "Debugpy version: 1.8.14\n",
      "Pyspark version: 3.5.5\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import pandas as pd\n",
    "    import debugpy\n",
    "    import pyspark\n",
    "    print(\"Pandas version:\", pd.__version__)\n",
    "    print(\"Debugpy version:\", debugpy.__version__)\n",
    "    print(\"Pyspark version:\", pyspark.__version__)\n",
    "except Exception as e:\n",
    "    print(\"An unexpected error occurred:\", e)\n",
    "    print(\"Please check your conda environment and package installations.\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/05/02 08:03:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ SparkSession creada exitosamente\n",
      "Versión de PySpark: 3.5.5\n",
      "\n",
      "✅ DataFrame creado exitosamente:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|product_id|demand|\n",
      "+----------+------+\n",
      "|   PVC_001|   150|\n",
      "|   PVC_002|   200|\n",
      "|   PVC_003|    75|\n",
      "+----------+------+\n",
      "\n",
      "\n",
      "📊 Demanda total calculada: 425 (Valor esperado: 425)\n",
      "🔍 Productos con demanda >100: 2 (Valor esperado: 2)\n",
      "\n",
      "🎛️ DataFrame con categorías de demanda:\n",
      "+----------+------+---------------+\n",
      "|product_id|demand|demand_category|\n",
      "+----------+------+---------------+\n",
      "|   PVC_001|   150|     Media/Baja|\n",
      "|   PVC_002|   200|           Alta|\n",
      "|   PVC_003|    75|     Media/Baja|\n",
      "+----------+------+---------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "💾 Datos escritos temporalmente en: /tmp/pyspark_test_output\n",
      "🔄 Lectura de datos verificada exitosamente\n",
      "\n",
      "🧹 Sesión de Spark cerrada correctamente\n",
      "\n",
      "🎉 ¡Todas las pruebas de PySpark se completaron exitosamente!\n"
     ]
    }
   ],
   "source": [
    "# Prueba de funcionamiento básico de PySpark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "\n",
    "def test_pyspark_environment():\n",
    "    \"\"\"\n",
    "    Prueba básica para verificar que PySpark está funcionando correctamente.\n",
    "    Crea una sesión, genera datos de prueba y ejecuta operaciones básicas.\n",
    "    \"\"\"    \n",
    "    # 1. Inicializar sesión de Spark\n",
    "    try:\n",
    "        spark = SparkSession.builder \\\n",
    "            .appName(\"PySparkTest\") \\\n",
    "            .getOrCreate()\n",
    "        \n",
    "        print(\"✅ SparkSession creada exitosamente\")\n",
    "        print(f\"Versión de PySpark: {spark.version}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error al crear SparkSession: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "    # 2. Crear DataFrame de prueba\n",
    "    test_data = [(\"PVC_001\", 150), \n",
    "                 (\"PVC_002\", 200),\n",
    "                 (\"PVC_003\", 75)]\n",
    "    \n",
    "    try:\n",
    "        df = spark.createDataFrame(test_data, [\"product_id\", \"demand\"])\n",
    "        print(\"\\n✅ DataFrame creado exitosamente:\")\n",
    "        df.show()\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error al crear DataFrame: {str(e)}\")\n",
    "        spark.stop()\n",
    "        return False\n",
    "\n",
    "    # 3. Probar transformaciones básicas\n",
    "    try:\n",
    "        # Calcular demanda total\n",
    "        total_demand = df.agg(F.sum(\"demand\").alias(\"total_demand\")).first()[0]\n",
    "        print(f\"\\n📊 Demanda total calculada: {total_demand} (Valor esperado: 425)\")\n",
    "        \n",
    "        # Filtrar productos con demanda > 100\n",
    "        high_demand = df.filter(col(\"demand\") > 100).count()\n",
    "        print(f\"🔍 Productos con demanda >100: {high_demand} (Valor esperado: 2)\")\n",
    "        \n",
    "        # Agregar columna calculada\n",
    "        df = df.withColumn(\"demand_category\", \n",
    "                          F.when(col(\"demand\") > 150, \"Alta\")\n",
    "                           .otherwise(\"Media/Baja\"))\n",
    "        print(\"\\n🎛️ DataFrame con categorías de demanda:\")\n",
    "        df.show()\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error en transformaciones: {str(e)}\")\n",
    "        spark.stop()\n",
    "        return False\n",
    "\n",
    "    # 4. Probar escritura temporal (modo seguro)\n",
    "    try:\n",
    "        temp_path = \"/tmp/pyspark_test_output\"\n",
    "        df.write.mode(\"overwrite\").parquet(temp_path)\n",
    "        print(f\"\\n💾 Datos escritos temporalmente en: {temp_path}\")\n",
    "        \n",
    "        # Leer datos guardados para verificación\n",
    "        df_read = spark.read.parquet(temp_path)\n",
    "        if df_read.count() == df.count():\n",
    "            print(\"🔄 Lectura de datos verificada exitosamente\")\n",
    "        else:\n",
    "            raise ValueError(\"Conteo de registros no coincide\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error en escritura/lectura: {str(e)}\")\n",
    "        spark.stop()\n",
    "        return False\n",
    "\n",
    "    # 5. Limpieza\n",
    "    spark.stop()\n",
    "    print(\"\\n🧹 Sesión de Spark cerrada correctamente\")\n",
    "    return True\n",
    "\n",
    "# Ejecutar prueba\n",
    "if __name__ == \"__main__\":\n",
    "    success = test_pyspark_environment()\n",
    "    if success:\n",
    "        print(\"\\n🎉 ¡Todas las pruebas de PySpark se completaron exitosamente!\")\n",
    "    else:\n",
    "        print(\"\\n🔴 Se encontraron problemas en la configuración de PySpark\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
